{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import scipy\n",
    "import yfinance as yf\n",
    "\n",
    "from neurotrader.download_data import download_df\n",
    "from neurotrader.directional_change import directional_change\n",
    "from neurotrader.perceptually_important import find_pips\n",
    "from neurotrader.head_shoulders import find_hs_patterns, get_pattern_return, load_attributes, HSPattern"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T19:39:31.922305Z",
     "start_time": "2024-04-22T19:39:31.917798Z"
    }
   },
   "id": "f3a08e8ff7897739",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reversal Pattern Detection Algorithm\n",
    "- Look at the 1 day intervals for now\n",
    "- Want to look at min by min at some point\n",
    "- Goal: If a pattern is detected, how much wieght should we give the buying/selling power of that pattern\n",
    "- AKA HOW ACCURATE THAT PATTERN IS FOR a certain stock (Profit factor)\n",
    "- See which patterns are most common\n",
    "- Look for a way to add an \"Early Detection\" of a pattern\n",
    "\n",
    "## TODO:\n",
    "- Run each program to see output, see how to generate data we can add to neural network\n",
    "- \n",
    "\n",
    "## How to apply to a neural network\n",
    "- For a stock, determine what error threshold to use by calculating the profit factor on known data\n",
    "-   HAVE TO OPTIMIZE HIS CODE FOR THIS APPROACH\n",
    "- Determine most common pattern\n",
    "- Determine most profitable pattern\n",
    "- Determine most accurate pattern\n",
    "- Find a way to detect patterns before the occure (test to see if market finishes the pattern)\n",
    "- Mess with different exit methods. Those are the hyperparameters\n",
    "- Run this on different stock\n",
    "\n",
    "### Idea:\n",
    "Train a NN to detect different patterns, testing different exit strategies on each pattern. Have it assign a buy/sell confidence value to these patterns. Then test this on unseen new data. Try to impliment flag detection here too\n",
    "\n",
    "We can further test this by training the network on each stock individually, trying to make predictions off of early identification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b09f16610e9058de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Different Algorithms for finding local extrema\n",
    "- Rolling Window\n",
    "- Directional Change\n",
    "- Perceptually Important Points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fabc61f1ce6310b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Trendline parameter\n",
    "lookback = 30\n",
    "data = download_df('AAPL', '5y')\n",
    "data.head(1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc124f7a85bd9344"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ROLLING WINDOW ALGORITHM\n",
    "# Use Scipy to get local extrema. BE CAREFUL NOT TO CHEAT WITH FUTURE DATA\n",
    "# Use close data because it is more stable than adj high and adj low\n",
    "arr = data['close'].to_numpy()\n",
    "bottoms = scipy.signal.argrelextrema(arr, np.less, order=3)\n",
    "tops = scipy.signal.argrelextrema(arr, np.greater, order=3)\n",
    "print(bottoms[0][0:11])\n",
    "print(tops[0][0:11])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0af014db6863118"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Perceptually Important Points\n",
    "PIP = 10\n",
    "pips_x, pips_y = find_pips(arr, PIP, 1)\n",
    "print(pips_x)\n",
    "print(pips_y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c15b67b8295fe61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building an ML model to detect patterns in a rolling window.\n",
    "Abstract: We want to use mathematical equations to detect patterns in our stock data in our data. We will look at those patterns and tie a value to them. We will then use a rolling window technique to make calculations on unseen data???\n",
    "- Use a 72-hour trend rolling window\n",
    "- LOOK FOR FEATURES that could show a trend\n",
    "- The Head and Shoulders is not a common occurance. Look to suplement this data with other patterns?\n",
    "- A lot of papers and programs create a bunch of synthetic data to train models on\n",
    "- This might be the best option here."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "192f1d2efb62c753"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Head and Shoulders\n",
    "- Possible option: Loop through every single one of the stock market top 500 and find the patterns. See how many there are?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5471ca8569a7553b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "data = download_df(ticker=ticker, interval='1d', period='max')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfcfbb481efa5358"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Detect HS in our dataset:\n",
    "# Convert our data to a logorithmic form and then only select the \"close\" column\n",
    "data_norm = np.log(data)\n",
    "dat_slice = data_norm['close'].to_numpy()\n",
    "\n",
    "# Find HS Patterns:\n",
    "hs_patterns, ihs_patterns = find_hs_patterns(dat_slice, 6, early_find=False)\n",
    "hs_df = pd.DataFrame()\n",
    "hs_df = load_attributes(dat_slice, hs_df, hs_patterns, len(data))\n",
    "ihs_df = pd.DataFrame()\n",
    "ihs_df = load_attributes(dat_slice, ihs_df, ihs_patterns, len(data))\n",
    "\n",
    "print(f\"We detected {len(hs_patterns)} hs and {len(ihs_patterns)}\"\n",
    "      f\" inverted hs out of {len(data)} data points\")\n",
    "print(f\"Data time range: {data.index[0]} to {data.index[-1]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1edd4085cdaff5f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hs_patterns[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e316768aaaf657d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_hs(data_norm, ticker, hs_patterns[0], pad=6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77be4da0850d8a96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Goal Here\n",
    "1) Test to see how the model when trained on hourly, minute, and daily data\n",
    "2) Train the data on both synthetic and real data. See how that effects pattern recognition\n",
    "    - NEED TO LEARN HOW TO GENERATE SYNTHETIC STOCK DATA\n",
    "3) TEST ALL THREE HS CALCULATIONS TO SEE WHICH ONE IS MORE ROBUST/ACCURATE!!!!\n",
    "    - Neurotraders\n",
    "    - CodeTrading\n",
    "    - Medium's\n",
    "4) Investigate the approach given by the paper from Seoul National University\n",
    "    - This may not be useful because they use a ton of different patterns. Interesting read about what type of model to use\n",
    "5) Have Neural Network add a buy/sell weight to each pattern after seeing if the stock went up or down after. Need to add manually?\n",
    "\n",
    "\n",
    "BREAK DATA INTO TRAINING AND TEST DATA FOR REAL DATA\n",
    "FOR SYNTHETIC DATA, TEST ON SAME TESTING DATA AS OTHER MODEL."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b0c74c1a9dd733e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1: Neurotraders Algorithm\n",
    "This code focuses on capturing time periods of code instead of images of code. Graphs can be generated as needed however. There is a possible way to do this automatically"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7705a4e480916549"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read and print the stock tickers that make up S&P500\n",
    "tickers = pd.read_html(\n",
    "    'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "\n",
    "# Get the data for these tickers from yahoo finance\n",
    "# yf_top500 = yf.download(tickers.Symbol.to_list(), interval='60m', period='2y', auto_adjust=True)['Close']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T19:39:36.301008Z",
     "start_time": "2024-04-22T19:39:35.951472Z"
    }
   },
   "id": "bffa37ff3b6ee7cf",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the data for these tickers from yahoo finance\n",
    "# Downloading this data because it is very time-consuming and I don't want to make \n",
    "#   repeated calls to yfinance\n",
    "# COMMENTING OUT TO AVOID DOING THIS AGAIN\n",
    "# for ticker in tickers.Symbol.to_list():\n",
    "#     df = download_df(ticker=ticker, period='2y', interval='60m')\n",
    "#     ticker_name = 'data/' + ticker + '_data.csv'\n",
    "#     df.to_csv(ticker_name, index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac4a6cf62014a8ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a dictionary to store data\n",
    "# Use ticker names as key\n",
    "l_yf_top500_norm = {}\n",
    "# For each ticker\n",
    "for ticker in tickers.Symbol.to_list()[0:2]:\n",
    "    try:\n",
    "        # Get the data from the local files and apply logarithmic transformations to it\n",
    "        data = pd.read_csv('data/' + ticker + '_data.csv', index_col=None, header=0)\n",
    "        # Place the datetime in a temp dataset\n",
    "        temp = data['Datetime']\n",
    "        # Apply numeric and log to the data\n",
    "        data = data.apply(pd.to_numeric, errors='coerce')\n",
    "        data = np.log(data)\n",
    "        # Add the datetime we saved earlier back in\n",
    "        data['Datetime'] = temp\n",
    "        data.index = pd.DatetimeIndex(data['Datetime'])\n",
    "        # Get the close data and find the HS and IHS patterns\n",
    "        dat_slice = data['close'].to_numpy()\n",
    "        hs_patterns, ihs_patterns = find_hs_patterns(dat_slice, 6, early_find=False)\n",
    "        # # hs_df = pd.DataFrame()\n",
    "        # # ihs_df = pd.DataFrame()\n",
    "        # # hs_df = load_attributes(dat_slice, hs_df, hs_patterns, len(data))\n",
    "        # # ihs_df = load_attributes(dat_slice, ihs_df, ihs_patterns, len(data))\n",
    "        # Store the data, hs, IHS with the ticker name as key\n",
    "        l_yf_top500_norm.update({ticker: [data, hs_patterns, ihs_patterns]})\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on ticker {ticker} with exception {e}\")\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T19:39:47.830152Z",
     "start_time": "2024-04-22T19:39:47.759545Z"
    }
   },
   "id": "ca578520c1bce2ee",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ticker MMM there are 1 hs patterns and 3 inverted hs patterns\n",
      "For ticker AOS there are 1 hs patterns and 3 inverted hs patterns\n"
     ]
    }
   ],
   "source": [
    "for i in l_yf_top500_norm:\n",
    "    print(f\"For ticker {i} there are {len(l_yf_top500_norm[i][1])} hs patterns and \"\n",
    "              f\"{len(l_yf_top500_norm[i][2])} inverted hs patterns\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T19:39:49.977940Z",
     "start_time": "2024-04-22T19:39:49.974435Z"
    }
   },
   "id": "92eb24602b154cd0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_simple_hs(candle_data: pd.DataFrame, ticker: str, pat: HSPattern, pad: int = 2):\n",
    "    if pad < 0:\n",
    "        pad = 0\n",
    "    \n",
    "    data = candle_data.iloc[pat.start_i:pat.break_i + 1 + pad]\n",
    "    fname = \"images/hs/\" + ticker + '_' + str(pat.start_i) + '_' + str(pat.break_i) + \".png\"\n",
    "    \n",
    "    mpf.plot(data, type='candle', axisoff=True, style = 'classic', savefig=dict(fname=fname, dpi=144))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:01:54.332415Z",
     "start_time": "2024-04-22T20:01:54.328909Z"
    }
   },
   "id": "e215aee794aaf099",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ticker MMM there are 1 hs patterns and 3 inverted hs patterns\n",
      "For ticker AOS there are 1 hs patterns and 3 inverted hs patterns\n"
     ]
    }
   ],
   "source": [
    "for ticker in l_yf_top500_norm:\n",
    "    num_hs = len(l_yf_top500_norm[ticker][1])\n",
    "    num_ihs = len(l_yf_top500_norm[ticker][2])\n",
    "    \n",
    "    print(f\"For ticker {ticker} there are {num_hs} hs patterns and \"\n",
    "              f\"{num_ihs} inverted hs patterns\")\n",
    "    \n",
    "    for i in range(num_hs):\n",
    "        candle_data = l_yf_top500_norm[ticker][0]\n",
    "        pat = l_yf_top500_norm[ticker][1][i]\n",
    "        plot_simple_hs(candle_data, ticker, pat, 2)\n",
    "        \n",
    "    for i in range(num_ihs):\n",
    "        candle_data = l_yf_top500_norm[ticker][0]\n",
    "        pat = l_yf_top500_norm[ticker][2][i]\n",
    "        plot_simple_hs(candle_data, ticker, pat, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:02:09.728478Z",
     "start_time": "2024-04-22T20:02:09.275786Z"
    }
   },
   "id": "3715c0974d07d738",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Unrecognized kwarg=\"background\"'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m candle_data \u001B[38;5;241m=\u001B[39m l_yf_top500_norm[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMMM\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      4\u001B[0m pat \u001B[38;5;241m=\u001B[39m l_yf_top500_norm[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMMM\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m----> 5\u001B[0m \u001B[43mplot_simple_hs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcandle_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMMM\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[50], line 8\u001B[0m, in \u001B[0;36mplot_simple_hs\u001B[1;34m(candle_data, ticker, pat, pad)\u001B[0m\n\u001B[0;32m      5\u001B[0m data \u001B[38;5;241m=\u001B[39m candle_data\u001B[38;5;241m.\u001B[39miloc[pat\u001B[38;5;241m.\u001B[39mstart_i:pat\u001B[38;5;241m.\u001B[39mbreak_i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m pad]\n\u001B[0;32m      6\u001B[0m fname \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages/hs/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m ticker \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(pat\u001B[38;5;241m.\u001B[39mstart_i) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(pat\u001B[38;5;241m.\u001B[39mbreak_i) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mmpf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcandle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackground\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdark\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxisoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclassic\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msavefig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m144\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\Documents\\SchoolStuff\\spring2024\\dataScience\\finalProject\\venv\\Lib\\site-packages\\mplfinance\\plotting.py:412\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(data, **kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m( data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs ):\n\u001B[0;32m    403\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;124;03m    Given a Pandas DataFrame containing columns Open,High,Low,Close and optionally Volume\u001B[39;00m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;124;03m    with a DatetimeIndex, plot the data.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;124;03m    Also provide ability to plot trading signals, and/or addtional user-defined data.\u001B[39;00m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 412\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[43m_process_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_valid_plot_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;66;03m# translate alias types:\u001B[39;00m\n\u001B[0;32m    415\u001B[0m     config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m _get_valid_plot_types(config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\Documents\\SchoolStuff\\spring2024\\dataScience\\finalProject\\venv\\Lib\\site-packages\\mplfinance\\_arg_validators.py:339\u001B[0m, in \u001B[0;36m_process_kwargs\u001B[1;34m(kwargs, vkwargs)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m vkwargs:\n\u001B[1;32m--> 339\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnrecognized kwarg=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(key)\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    341\u001B[0m         value \u001B[38;5;241m=\u001B[39m kwargs[key]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Unrecognized kwarg=\"background\"'"
     ]
    }
   ],
   "source": [
    "# Select the data from the dataframe using the ticker name as a key\n",
    "# Get the hs pattern\n",
    "candle_data = l_yf_top500_norm['MMM'][0]\n",
    "pat = l_yf_top500_norm['MMM'][2][1]\n",
    "plot_simple_hs(candle_data, 'MMM', pat, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:00:35.229845Z",
     "start_time": "2024-04-22T20:00:35.037050Z"
    }
   },
   "id": "bcee0302ac69aad7",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bd5792e6100cb832"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
