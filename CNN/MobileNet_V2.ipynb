{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2410f2bada8e8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9cd6425650704",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Convert images from pixals into data, then use pretrained model to accurately classify the stocks\n",
    "- Mathematical detection algorithms are at best 84% accurate. Goal is to \n",
    "- https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "- Make a requirements text file\n",
    "- We do not apply data augmentation because we already have patterns classified as up or down, and flipping them would be counterintuitive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0ee41a9636bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MobileNet V2 Trained by Google"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ecc2b2347db0ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335e19cbdd38f9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "# \n",
    "# from tensorflow import keras\n",
    "# print(\"TensorFlow version: \", tf.__version__)\n",
    "# assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "#     \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "# print(tensorboard.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b2021336e99c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baceab8354a8b153",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Paths: For local machine\n",
    "train_dir = 'directory to train images here'\n",
    "validation_dir = 'directory to validation images here'\n",
    "\n",
    "# train_dir = 'C:/Users/Nick/Desktop/stock images/train'\n",
    "# validation_dir = 'C:/Users/Nick/Desktop/stock images/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c86a7422ff6d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create training and validation dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            color_mode='rgb',\n",
    "                                                            image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 color_mode='rgb',\n",
    "                                                                 image_size=(IMG_SIZE, IMG_SIZE))\n",
    "class_names = train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4c100fb0d908f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a test set\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "# Rescale the images from [-1 to 1] vs [0 to 255]\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39113a024e5db3df",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE) + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e05434194b03e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This feature extractor converts each 255x255 image into a 5x5x1280 block of features\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdb33f4fcb9884",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unfreeze this to train\n",
    "base_model.trainable = False\n",
    "\n",
    "# Adding a classification head using max\n",
    "global_max_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
    "feature_batch_max = global_max_layer(feature_batch)\n",
    "# print(feature_batch_average.shape)\n",
    "\n",
    "# Add a dense layer to convert it to a single prediction per image , activation='softmax'\n",
    "prediction_layer = tf.keras.layers.Dense(len(class_names)) \n",
    "prediction_batch = prediction_layer(feature_batch_max)\n",
    "# print(prediction_batch.shape)\n",
    "\n",
    "# Process the inputs\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# Add the preprocessing layer\n",
    "x = preprocess_input(inputs)\n",
    "# Add the base model after, keeping training to false\n",
    "x = base_model(x, training=False)\n",
    "# Add max pooling layer\n",
    "x = global_max_layer(x)\n",
    "# Add dropout layer\n",
    "# x = tf.keras.layers.Dropout(0)(x)\n",
    "# Add softmax prediction layer\n",
    "outputs = prediction_layer(x)\n",
    "# Create a model from inputs, outputs.\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8604d15ceed5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c75cb67a26d13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676bd207c92643c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # False when we have a softmax layer\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9d2da7571e2e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"C:/Users/Nick/Documents/SchoolStuff/spring2024/machineLearning/final_project/CNN/logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2641425b961f8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the top layer\n",
    "initial_epochs = 5\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    steps_per_epoch=5,\n",
    "                    validation_data=validation_dataset,\n",
    "                    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492f7380af3b1a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "# \n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0, .5])\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# \n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.ylabel('Cross Entropy')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylim([0, 10])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44995519b11c85d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Customization\n",
    "1) Feature Extraction\n",
    "2) Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464e981f00f2d5f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcb09b703aa5a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 130\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df5e4b48494ed6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6c9334ff2d9dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # False when we have a Softmax layer\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcdf30b27e330d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=len(history.epoch),\n",
    "                         steps_per_epoch=5,\n",
    "                         validation_data=validation_dataset,\n",
    "                         validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c38e6490bb84be",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ab22ee0bbe9b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0193ea8c91d943",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0, .5])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 8.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b517250283fea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a softmax layer to our model and apply our test data\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = probability_model.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7ceb6d6efd1ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4daaa4ff9673eac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  guess = str(class_names[np.argmax(predictions[i+9])])\n",
    "  actual = str(class_names[label_batch[i+9]])\n",
    "  title = \"Prediction: \" + guess + \"\\n\" + \"Actual: \" + actual\n",
    "  plt.title(title)\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bdbddb8403c1e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs --host localhost --port 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
